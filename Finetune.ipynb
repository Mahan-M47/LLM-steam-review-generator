{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDWqKrwH1uw_"
      },
      "source": [
        "# Fine-tuninig the LLM Model\n",
        "Mahan Madani - Mohammad Mehdi Begmaz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOoq6QpD1uxC"
      },
      "source": [
        "## Load Dataset and important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NJXP9Phy1uxC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    Trainer)\n",
        "\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "\n",
        "from pynvml import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3_-hrFkP1uxD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG4o9Uzk1uxD",
        "outputId": "cc070ac6-44bb-4aef-85da-536bab7063ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['review', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score',\n",
            "       'word_count', 'profanity'],\n",
            "      dtype='object')\n",
            "(10000, 7)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"./dataset/BG3_reviews_preprocessed.csv\")  # load the preprocessed version of the dataset\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GopRdoFc1uxD"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tzr2ziNS1uxD"
      },
      "outputs": [],
      "source": [
        "model_name = 'gpt2'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, ).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Load model if it alrady exists\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"./model/v2\").to(device)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"./model/v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh08ISMp1uxE"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "D0889FVI1uxE",
        "outputId": "33441d5d-bb16-4d61-b045-90e04b81872c"
      },
      "outputs": [],
      "source": [
        "# add pad token if none exists\n",
        "# if tokenizer.pad_token is None:\n",
        "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "#     model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['review', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'word_count', 'profanity'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = Dataset.from_pandas(df)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TokenizerWrapper:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def tokenize_function(self, examples):\n",
        "        self.tokenizer.truncation_side = \"right\"\n",
        "\n",
        "        return self.tokenizer(\n",
        "            examples[\"review\"],\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aee5071c248b415692de1d22f929b029",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer_wrapper = TokenizerWrapper(tokenizer)\n",
        "\n",
        "tokenized_dataset = train_dataset.map(\n",
        "    tokenizer_wrapper.tokenize_function,\n",
        "    num_proc=4,\n",
        "    remove_columns=train_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0f48a43b247475583e2ad96af184985",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def group_texts(examples):\n",
        "    block_size = 128\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of block_size.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.map(group_texts, batched=True, num_proc=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4xAv1-l1uxF"
      },
      "source": [
        "# Fine-tune model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    # Note that other metrics may not have a `use_aggregator` parameter\n",
        "    # and thus will return a list, computing a metric for each sentence.\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gh-4KpEAI036"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "\n",
        "    # Prints the number of trainable parameters in the model.\n",
        "\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj4nKs7ANHsv",
        "outputId": "79ca1d55-6fb9-4894-de99-713d732b76ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 124439808 || all params: 124439808 || trainable%: 100.0\n"
          ]
        }
      ],
      "source": [
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGDmKBkO4RQt",
        "outputId": "0dc2358d-a8fb-4143-fad1-1dbc85948fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 589824 || all params: 125029632 || trainable%: 0.4717473694555863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Mahan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\peft\\tuners\\lora\\model.py:347: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"c_attn\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WsP0fQSu4k1S"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1JYb2yCl4kzD"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= \"gpt2-lora-review_generation\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    # save_strategy=\"epoch\",\n",
        "    # load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "LYgq6PVq4oe-",
        "outputId": "a293d403-74cb-477e-b819-28f885041a51"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bd066aa55754709805841629ea122a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/14710 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checkpoint destination directory gpt2-lora-review_generation\\checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.8665, 'learning_rate': 0.0009660095173351462, 'epoch': 0.17}\n",
            "{'loss': 3.7741, 'learning_rate': 0.0009320190346702923, 'epoch': 0.34}\n",
            "{'loss': 3.7302, 'learning_rate': 0.0008980285520054386, 'epoch': 0.51}\n",
            "{'loss': 3.6985, 'learning_rate': 0.0008640380693405847, 'epoch': 0.68}\n",
            "{'loss': 3.6728, 'learning_rate': 0.0008300475866757308, 'epoch': 0.85}\n",
            "{'loss': 3.671, 'learning_rate': 0.0007960571040108769, 'epoch': 1.02}\n",
            "{'loss': 3.6519, 'learning_rate': 0.0007620666213460231, 'epoch': 1.19}\n",
            "{'loss': 3.6329, 'learning_rate': 0.0007280761386811693, 'epoch': 1.36}\n",
            "{'loss': 3.6357, 'learning_rate': 0.0006940856560163155, 'epoch': 1.53}\n",
            "{'loss': 3.6237, 'learning_rate': 0.0006600951733514616, 'epoch': 1.7}\n",
            "{'loss': 3.608, 'learning_rate': 0.0006261046906866078, 'epoch': 1.87}\n",
            "{'loss': 3.597, 'learning_rate': 0.0005921142080217539, 'epoch': 2.04}\n",
            "{'loss': 3.5779, 'learning_rate': 0.0005581237253569001, 'epoch': 2.21}\n",
            "{'loss': 3.5726, 'learning_rate': 0.0005241332426920462, 'epoch': 2.38}\n",
            "{'loss': 3.5707, 'learning_rate': 0.0004901427600271924, 'epoch': 2.55}\n",
            "{'loss': 3.5747, 'learning_rate': 0.00045615227736233853, 'epoch': 2.72}\n",
            "{'loss': 3.5809, 'learning_rate': 0.00042216179469748474, 'epoch': 2.89}\n",
            "{'loss': 3.5586, 'learning_rate': 0.0003881713120326309, 'epoch': 3.06}\n",
            "{'loss': 3.5401, 'learning_rate': 0.00035418082936777704, 'epoch': 3.23}\n",
            "{'loss': 3.5381, 'learning_rate': 0.0003201903467029232, 'epoch': 3.4}\n",
            "{'loss': 3.5261, 'learning_rate': 0.00028619986403806934, 'epoch': 3.57}\n",
            "{'loss': 3.5328, 'learning_rate': 0.00025220938137321554, 'epoch': 3.74}\n",
            "{'loss': 3.5473, 'learning_rate': 0.00021821889870836167, 'epoch': 3.91}\n",
            "{'loss': 3.5286, 'learning_rate': 0.00018422841604350782, 'epoch': 4.08}\n",
            "{'loss': 3.5085, 'learning_rate': 0.000150237933378654, 'epoch': 4.25}\n",
            "{'loss': 3.5253, 'learning_rate': 0.00011624745071380013, 'epoch': 4.42}\n",
            "{'loss': 3.5102, 'learning_rate': 8.22569680489463e-05, 'epoch': 4.59}\n",
            "{'loss': 3.5084, 'learning_rate': 4.826648538409246e-05, 'epoch': 4.76}\n",
            "{'loss': 3.5, 'learning_rate': 1.4276002719238612e-05, 'epoch': 4.93}\n",
            "{'train_runtime': 1773.6485, 'train_samples_per_second': 33.172, 'train_steps_per_second': 8.294, 'train_loss': 3.597148330449896, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    # train_dataset=tokenized_dataset[\"train\"],\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# train model\n",
        "results = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "\n",
        "\n",
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory occupied: 535 MB.\n"
          ]
        }
      ],
      "source": [
        "print_gpu_utilization()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 1773.65\n",
            "Samples/second: 33.17\n",
            "GPU memory occupied: 2180 MB.\n"
          ]
        }
      ],
      "source": [
        "print_summary(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "b942AC6J1uxF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./model/v2\\\\tokenizer_config.json',\n",
              " './model/v2\\\\special_tokens_map.json',\n",
              " './model/v2\\\\vocab.json',\n",
              " './model/v2\\\\merges.txt',\n",
              " './model/v2\\\\added_tokens.json',\n",
              " './model/v2\\\\tokenizer.json')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# save model parameters\n",
        "model.save_pretrained(\"./model/v2\")\n",
        "tokenizer.save_pretrained(\"./model/v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghvJS_V_1uxF"
      },
      "source": [
        "# Generate Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vsV5wekl1uxF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "i just have one review for this game that has me wondering how it looks, and in the end it feels like the game is more finished than i expected. i have already got into it and am still in early access so it is buggy, and it seems like this isn't going to be the final full release or release. i don't have a large budget, or something to play with, but the devs really managed to put this game through their paces with amazing design and gameplay\n"
          ]
        }
      ],
      "source": [
        "generated_text = model.generate(max_length=100, do_sample=True, top_k=50, top_p=0.95)\n",
        "print(tokenizer.decode(generated_text[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i think that it really is what they want to do. the music is so great (i have played over 70 hours), the voice actors are so much fun and are making you cry.  that is what these games need to be. they just need to do more with their time  but it isn't enough for a studio. they can have a good time right? at least this is the way they are going.a perfect example of the kind of thing you can expect if you buy a\n"
          ]
        }
      ],
      "source": [
        "prompt = 'i think that'\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "inputs.to(device)\n",
        "generated_text = model.generate(input_ids= inputs, max_length=100, do_sample=True, top_k=50, top_p=0.95)\n",
        "\n",
        "print(tokenizer.decode(generated_text[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")\n",
        "# Perplexity: 49.61"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
