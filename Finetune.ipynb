{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDWqKrwH1uw_"
      },
      "source": [
        "# Fine-tuninig the LLM Model\n",
        "Mahan Madani - Mohammad Mehdi Begmaz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOoq6QpD1uxC"
      },
      "source": [
        "## Load Dataset and important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NJXP9Phy1uxC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    Trainer)\n",
        "\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "\n",
        "from pynvml import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3_-hrFkP1uxD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG4o9Uzk1uxD",
        "outputId": "cc070ac6-44bb-4aef-85da-536bab7063ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['review', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score',\n",
            "       'word_count', 'profanity'],\n",
            "      dtype='object')\n",
            "(10000, 7)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"./dataset/BG3_reviews_preprocessed.csv\")  # load the preprocessed version of the dataset\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GopRdoFc1uxD"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tzr2ziNS1uxD"
      },
      "outputs": [],
      "source": [
        "model_name = 'gpt2'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model if it alrady exists\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"./model/v3\").to(device)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"./model/v3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh08ISMp1uxE"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "D0889FVI1uxE",
        "outputId": "33441d5d-bb16-4d61-b045-90e04b81872c"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['review', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'word_count', 'profanity'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = Dataset.from_pandas(df)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TokenizerWrapper:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def tokenize_function(self, examples):\n",
        "        self.tokenizer.truncation_side = \"right\"\n",
        "\n",
        "        return self.tokenizer(\n",
        "            examples[\"review\"],\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19a6fc75aad349f581326ae4fabc118c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer_wrapper = TokenizerWrapper(tokenizer)\n",
        "\n",
        "tokenized_dataset = train_dataset.map(\n",
        "    tokenizer_wrapper.tokenize_function,\n",
        "    num_proc=4,\n",
        "    remove_columns=train_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def group_texts(examples):\n",
        "#     block_size = 128\n",
        "#     # Concatenate all texts.\n",
        "#     concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "#     total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "\n",
        "#     # We drop the small remainder\n",
        "#     if total_length >= block_size:\n",
        "#         total_length = (total_length // block_size) * block_size\n",
        "\n",
        "#     # Split by chunks of block_size.\n",
        "#     result = {\n",
        "#         k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "#         for k, t in concatenated_examples.items()\n",
        "#     }\n",
        "#     result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "#     return result\n",
        "\n",
        "# tokenized_dataset = tokenized_dataset.map(group_texts, batched=True, num_proc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4xAv1-l1uxF"
      },
      "source": [
        "## Fine-tune model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    # Note that other metrics may not have a `use_aggregator` parameter\n",
        "    # and thus will return a list, computing a metric for each sentence.\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gh-4KpEAI036"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "\n",
        "    # Prints the number of trainable parameters in the model.\n",
        "\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj4nKs7ANHsv",
        "outputId": "79ca1d55-6fb9-4894-de99-713d732b76ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 0 || all params: 125029632 || trainable%: 0.0\n"
          ]
        }
      ],
      "source": [
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGDmKBkO4RQt",
        "outputId": "0dc2358d-a8fb-4143-fad1-1dbc85948fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 589824 || all params: 125029632 || trainable%: 0.4717473694555863\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"c_attn\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WsP0fQSu4k1S"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1JYb2yCl4kzD"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= \"gpt2-lora-review_generation\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "LYgq6PVq4oe-",
        "outputId": "a293d403-74cb-477e-b819-28f885041a51"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85a3b1713c1b49bf977f678a3021a277",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checkpoint destination directory gpt2-lora-review_generation\\checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.9106, 'learning_rate': 9.6e-05, 'epoch': 0.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checkpoint destination directory gpt2-lora-review_generation\\checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.7341, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.4}\n",
            "{'loss': 3.7167, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.6}\n",
            "{'loss': 3.6707, 'learning_rate': 8.4e-05, 'epoch': 0.8}\n",
            "{'loss': 3.6504, 'learning_rate': 8e-05, 'epoch': 1.0}\n",
            "{'loss': 3.6355, 'learning_rate': 7.6e-05, 'epoch': 1.2}\n",
            "{'loss': 3.6331, 'learning_rate': 7.2e-05, 'epoch': 1.4}\n",
            "{'loss': 3.6378, 'learning_rate': 6.800000000000001e-05, 'epoch': 1.6}\n",
            "{'loss': 3.5981, 'learning_rate': 6.400000000000001e-05, 'epoch': 1.8}\n",
            "{'loss': 3.6129, 'learning_rate': 6e-05, 'epoch': 2.0}\n",
            "{'loss': 3.5854, 'learning_rate': 5.6000000000000006e-05, 'epoch': 2.2}\n",
            "{'loss': 3.598, 'learning_rate': 5.2000000000000004e-05, 'epoch': 2.4}\n",
            "{'loss': 3.5874, 'learning_rate': 4.8e-05, 'epoch': 2.6}\n",
            "{'loss': 3.5846, 'learning_rate': 4.4000000000000006e-05, 'epoch': 2.8}\n",
            "{'loss': 3.5922, 'learning_rate': 4e-05, 'epoch': 3.0}\n",
            "{'loss': 3.5474, 'learning_rate': 3.6e-05, 'epoch': 3.2}\n",
            "{'loss': 3.583, 'learning_rate': 3.2000000000000005e-05, 'epoch': 3.4}\n",
            "{'loss': 3.5934, 'learning_rate': 2.8000000000000003e-05, 'epoch': 3.6}\n",
            "{'loss': 3.5654, 'learning_rate': 2.4e-05, 'epoch': 3.8}\n",
            "{'loss': 3.5962, 'learning_rate': 2e-05, 'epoch': 4.0}\n",
            "{'loss': 3.5738, 'learning_rate': 1.6000000000000003e-05, 'epoch': 4.2}\n",
            "{'loss': 3.5774, 'learning_rate': 1.2e-05, 'epoch': 4.4}\n",
            "{'loss': 3.5444, 'learning_rate': 8.000000000000001e-06, 'epoch': 4.6}\n",
            "{'loss': 3.5515, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.8}\n",
            "{'loss': 3.5702, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "{'train_runtime': 2613.5697, 'train_samples_per_second': 19.131, 'train_steps_per_second': 4.783, 'train_loss': 3.618012021484375, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# train model\n",
        "results = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "\n",
        "\n",
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory occupied: 6541 MB.\n"
          ]
        }
      ],
      "source": [
        "print_gpu_utilization()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 2613.57\n",
            "Samples/second: 19.13\n",
            "GPU memory occupied: 6547 MB.\n"
          ]
        }
      ],
      "source": [
        "print_summary(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b942AC6J1uxF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./model/v4\\\\tokenizer_config.json',\n",
              " './model/v4\\\\special_tokens_map.json',\n",
              " './model/v4\\\\vocab.json',\n",
              " './model/v4\\\\merges.txt',\n",
              " './model/v4\\\\added_tokens.json',\n",
              " './model/v4\\\\tokenizer.json')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# save model parameters\n",
        "model.save_pretrained(\"./model/v4\")\n",
        "tokenizer.save_pretrained(\"./model/v4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghvJS_V_1uxF"
      },
      "source": [
        "## Generate Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers.utils import logging\n",
        "import transformers\n",
        "\n",
        "logging.set_verbosity(transformers.logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vsV5wekl1uxF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " the best game i've played. most likely the best and most played so far and i think i will continue to play this game ever since i found i could make an honest living from what i have made and it will be a wonderful experience for everyone and can't wait for the final release. for the true epic, i cant wait to see it. that's good in my book!  great for people who would like to see a game that is truly unique in one of those rare times\n"
          ]
        }
      ],
      "source": [
        "generated_text = model.generate(max_length=100, do_sample=True, top_k=50, top_p=0.95)\n",
        "print(tokenizer.decode(generated_text[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i think that the voice acting in baldurs gate 3 is so good it's worth it, the characters are engaging, and the story is all the more amazing for its story.   i'm just starting out and not the one i'm hoping for in the future. this version seems to have gotten me thinking so much that it was only in early access that i played the beta and got the game's release out in early access.  if you're thinking of playing baldurs gate 3 and\n"
          ]
        }
      ],
      "source": [
        "prompt = 'i think that'\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "inputs = inputs.to(device)\n",
        "generated_text = model.generate(input_ids=inputs, max_length=100, do_sample=True, top_k=50, top_p=0.95)\n",
        "\n",
        "print(tokenizer.decode(generated_text[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
