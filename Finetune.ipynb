{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDWqKrwH1uw_"
      },
      "source": [
        "# Fine-tuninig the LLM Model\n",
        "Mahan Madani - Mohammad Mehdi Begmaz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOoq6QpD1uxC"
      },
      "source": [
        "## Load Dataset and important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NJXP9Phy1uxC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    Trainer)\n",
        "\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "\n",
        "from pynvml import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3_-hrFkP1uxD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG4o9Uzk1uxD",
        "outputId": "cc070ac6-44bb-4aef-85da-536bab7063ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['review', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score',\n",
            "       'word_count', 'profanity'],\n",
            "      dtype='object')\n",
            "(10000, 7)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"./dataset/BG3_reviews_preprocessed.csv\")  # load the preprocessed version of the dataset\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GopRdoFc1uxD"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tzr2ziNS1uxD"
      },
      "outputs": [],
      "source": [
        "model_name = 'gpt2'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model if it alrady exists\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./model/v2\").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./model/v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh08ISMp1uxE"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "D0889FVI1uxE",
        "outputId": "33441d5d-bb16-4d61-b045-90e04b81872c"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['review', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'word_count', 'profanity'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = Dataset.from_pandas(df)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TokenizerWrapper:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def tokenize_function(self, examples):\n",
        "        self.tokenizer.truncation_side = \"right\"\n",
        "\n",
        "        return self.tokenizer(\n",
        "            examples[\"review\"],\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0fee998aa6d4c1db2b2e8a7374574bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer_wrapper = TokenizerWrapper(tokenizer)\n",
        "\n",
        "tokenized_dataset = train_dataset.map(\n",
        "    tokenizer_wrapper.tokenize_function,\n",
        "    num_proc=4,\n",
        "    remove_columns=train_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "778faaca7d954417a7ddeb5b1cc7198b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def group_texts(examples):\n",
        "    block_size = 128\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "\n",
        "    # We drop the small remainder\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "\n",
        "    # Split by chunks of block_size.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.map(group_texts, batched=True, num_proc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 11767\n",
              "})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4xAv1-l1uxF"
      },
      "source": [
        "# Fine-tune model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    # Note that other metrics may not have a `use_aggregator` parameter\n",
        "    # and thus will return a list, computing a metric for each sentence.\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "gh-4KpEAI036"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "\n",
        "    # Prints the number of trainable parameters in the model.\n",
        "\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj4nKs7ANHsv",
        "outputId": "79ca1d55-6fb9-4894-de99-713d732b76ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 589824 || all params: 125029632 || trainable%: 0.4717473694555863\n"
          ]
        }
      ],
      "source": [
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGDmKBkO4RQt",
        "outputId": "0dc2358d-a8fb-4143-fad1-1dbc85948fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 589824 || all params: 125029632 || trainable%: 0.4717473694555863\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"c_attn\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "WsP0fQSu4k1S"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "1JYb2yCl4kzD"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= \"gpt2-lora-review_generation\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "LYgq6PVq4oe-",
        "outputId": "a293d403-74cb-477e-b819-28f885041a51"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb6d8f81efbb4111a00b0a433f145f13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/14710 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 4.273, 'learning_rate': 1.3790754496286927e-05, 'epoch': 0.17}\n",
            "{'loss': 4.1017, 'learning_rate': 1.330550627333524e-05, 'epoch': 0.34}\n",
            "{'loss': 4.0187, 'learning_rate': 1.2820258050383554e-05, 'epoch': 0.51}\n",
            "{'loss': 3.9618, 'learning_rate': 1.2335009827431867e-05, 'epoch': 0.68}\n",
            "{'loss': 3.929, 'learning_rate': 1.184976160448018e-05, 'epoch': 0.85}\n",
            "{'loss': 3.9262, 'learning_rate': 1.1364513381528493e-05, 'epoch': 1.02}\n",
            "{'loss': 3.9182, 'learning_rate': 1.0879265158576808e-05, 'epoch': 1.19}\n",
            "{'loss': 3.8911, 'learning_rate': 1.0394016935625122e-05, 'epoch': 1.36}\n",
            "{'loss': 3.8867, 'learning_rate': 9.908768712673435e-06, 'epoch': 1.53}\n",
            "{'loss': 3.8707, 'learning_rate': 9.42352048972175e-06, 'epoch': 1.7}\n",
            "{'loss': 3.8624, 'learning_rate': 8.938272266770063e-06, 'epoch': 1.87}\n",
            "{'loss': 3.8538, 'learning_rate': 8.453024043818377e-06, 'epoch': 2.04}\n",
            "{'loss': 3.8538, 'learning_rate': 7.967775820866688e-06, 'epoch': 2.21}\n",
            "{'loss': 3.8437, 'learning_rate': 7.482527597915003e-06, 'epoch': 2.38}\n",
            "{'loss': 3.838, 'learning_rate': 6.997279374963317e-06, 'epoch': 2.55}\n",
            "{'loss': 3.8386, 'learning_rate': 6.512031152011631e-06, 'epoch': 2.72}\n",
            "{'loss': 3.8484, 'learning_rate': 6.026782929059944e-06, 'epoch': 2.89}\n",
            "{'loss': 3.8403, 'learning_rate': 5.541534706108258e-06, 'epoch': 3.06}\n",
            "{'loss': 3.8287, 'learning_rate': 5.056286483156571e-06, 'epoch': 3.23}\n",
            "{'loss': 3.8238, 'learning_rate': 4.571038260204886e-06, 'epoch': 3.4}\n",
            "{'loss': 3.8111, 'learning_rate': 4.085790037253199e-06, 'epoch': 3.57}\n",
            "{'loss': 3.8269, 'learning_rate': 3.600541814301513e-06, 'epoch': 3.74}\n",
            "{'loss': 3.8387, 'learning_rate': 3.1152935913498265e-06, 'epoch': 3.91}\n",
            "{'loss': 3.8255, 'learning_rate': 2.63004536839814e-06, 'epoch': 4.08}\n",
            "{'loss': 3.8157, 'learning_rate': 2.1447971454464536e-06, 'epoch': 4.25}\n",
            "{'loss': 3.8296, 'learning_rate': 1.6595489224947672e-06, 'epoch': 4.42}\n",
            "{'loss': 3.8271, 'learning_rate': 1.174300699543081e-06, 'epoch': 4.59}\n",
            "{'loss': 3.8197, 'learning_rate': 6.890524765913947e-07, 'epoch': 4.76}\n",
            "{'loss': 3.8103, 'learning_rate': 2.0380425363970825e-07, 'epoch': 4.93}\n",
            "{'train_runtime': 964.1681, 'train_samples_per_second': 61.022, 'train_steps_per_second': 15.257, 'train_loss': 3.8819982968245452, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# train model\n",
        "results = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "\n",
        "\n",
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory occupied: 2460 MB.\n"
          ]
        }
      ],
      "source": [
        "print_gpu_utilization()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 964.17\n",
            "Samples/second: 61.02\n",
            "GPU memory occupied: 2468 MB.\n"
          ]
        }
      ],
      "source": [
        "print_summary(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "b942AC6J1uxF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./model/v3\\\\tokenizer_config.json',\n",
              " './model/v3\\\\special_tokens_map.json',\n",
              " './model/v3\\\\vocab.json',\n",
              " './model/v3\\\\merges.txt',\n",
              " './model/v3\\\\added_tokens.json',\n",
              " './model/v3\\\\tokenizer.json')"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# save model parameters\n",
        "model.save_pretrained(\"./model/v3\")\n",
        "tokenizer.save_pretrained(\"./model/v3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghvJS_V_1uxF"
      },
      "source": [
        "# Generate Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "vsV5wekl1uxF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1 player, 3.5 hours of play. great game for a game like this, and i've played for years. its so simple. for the most people, you have a good, clear cut story, beautiful world, lots of quests and interesting character choices, many of the most important stuff that you're probably not used to. i'm so surprised this is even being released here. the best part is that it is currently priced at $29.99 for a 5 game game\n"
          ]
        }
      ],
      "source": [
        "generated_text = model.generate(max_length=100, do_sample=True, top_k=50, top_p=0.95)\n",
        "print(tokenizer.decode(generated_text[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i think that a person of the right age in a medium game of this quality, should make a real decision about the way they play.  of course they are going to like the games and we cannot imagine that any other single person would want to play as a young player.  and the game is great, so to say it was not a \"larian\" game was grossly under appreciated by me as the game is quite an interesting one and it seems like they could have put their money where\n"
          ]
        }
      ],
      "source": [
        "prompt = 'i think that'\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "inputs = inputs.to(device)\n",
        "generated_text = model.generate(input_ids=inputs, max_length=100, do_sample=True, top_k=50, top_p=0.95)\n",
        "\n",
        "print(tokenizer.decode(generated_text[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")\n",
        "# Perplexity: 49.61"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
